{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d6cc6-c045-4bdc-968d-3bd7a0fc5077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "from collections import defaultdict\n",
    "from typing import Any, Iterable, List, Optional, Tuple, Union\n",
    "from torch import Tensor\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sketchgraphs.data as datalib\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import NNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca5146-1dc8-4e3b-a4ca-8e8aa553d462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3186d9-3c0b-42ab-8da9-82a3ab3b74c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here is the modified to_networkx function that doesn't throw exceptions\n",
    "\n",
    "def from_networkx(\n",
    "    G: Any,\n",
    "    group_node_attrs: Optional[Union[List[str], all]] = None,\n",
    "    group_edge_attrs: Optional[Union[List[str], all]] = None,\n",
    ") -> 'torch_geometric.data.Data':\n",
    "    r\"\"\"Converts a :obj:`networkx.Graph` or :obj:`networkx.DiGraph` to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph or networkx.DiGraph): A networkx graph.\n",
    "        group_node_attrs (List[str] or all, optional): The node attributes to\n",
    "            be concatenated and added to :obj:`data.x`. (default: :obj:`None`)\n",
    "        group_edge_attrs (List[str] or all, optional): The edge attributes to\n",
    "            be concatenated and added to :obj:`data.edge_attr`.\n",
    "            (default: :obj:`None`)\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        All :attr:`group_node_attrs` and :attr:`group_edge_attrs` values must\n",
    "        be numeric.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> edge_index = torch.tensor([\n",
    "        ...     [0, 1, 1, 2, 2, 3],\n",
    "        ...     [1, 0, 2, 1, 3, 2],\n",
    "        ... ])\n",
    "        >>> data = Data(edge_index=edge_index, num_nodes=4)\n",
    "        >>> g = to_networkx(data)\n",
    "        >>> # A `Data` object is returned\n",
    "        >>> from_networkx(g)\n",
    "        Data(edge_index=[2, 6], num_nodes=4)\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "\n",
    "    from torch_geometric.data import Data\n",
    "\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "    G = G.to_directed() if not nx.is_directed(G) else G\n",
    "\n",
    "    if isinstance(G, (nx.MultiGraph, nx.MultiDiGraph)):\n",
    "        edges = list(G.edges(keys=False))\n",
    "    else:\n",
    "        edges = list(G.edges)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    data = defaultdict(list)\n",
    "\n",
    "    if G.number_of_nodes() > 0:\n",
    "        node_attrs = list(next(iter(G.nodes(data=True)))[-1].keys())\n",
    "    else:\n",
    "        node_attrs = {}\n",
    "\n",
    "    if G.number_of_edges() > 0:\n",
    "        edge_attrs = list(next(iter(G.edges(data=True)))[-1].keys())\n",
    "    else:\n",
    "        edge_attrs = {}\n",
    "\n",
    "    for i, (_, feat_dict) in enumerate(G.nodes(data=True)):\n",
    "        if set(feat_dict.keys()) != set(node_attrs):\n",
    "            raise ValueError('Not all nodes contain the same attributes')\n",
    "        for key, value in feat_dict.items():\n",
    "            data[str(key)].append(value)\n",
    "\n",
    "    for i, (_, _, feat_dict) in enumerate(G.edges(data=True)):\n",
    "        if set(feat_dict.keys()) != set(edge_attrs):\n",
    "            raise ValueError('Not all edges contain the same attributes')\n",
    "        for key, value in feat_dict.items():\n",
    "            key = f'edge_{key}' if key in node_attrs else key\n",
    "            data[str(key)].append(value)\n",
    "\n",
    "    for key, value in G.graph.items():\n",
    "        key = f'graph_{key}' if key in node_attrs else key\n",
    "        data[str(key)] = value\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, (tuple, list)) and isinstance(value[0], Tensor):\n",
    "            data[key] = torch.stack(value, dim=0)\n",
    "        else:\n",
    "            try:\n",
    "                data[key] = torch.tensor(value)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    data['edge_index'] = edge_index.view(2, -1)\n",
    "    data = Data.from_dict(data)\n",
    "\n",
    "    if group_node_attrs is all:\n",
    "        group_node_attrs = list(node_attrs)\n",
    "    if group_node_attrs is not None:\n",
    "        xs = []\n",
    "        for key in group_node_attrs:\n",
    "            x = data[key]\n",
    "            x = x.view(-1, 1) if x.dim() <= 1 else x\n",
    "            xs.append(x)\n",
    "            del data[key]\n",
    "        data.x = torch.cat(xs, dim=-1)\n",
    "\n",
    "    if group_edge_attrs is all:\n",
    "        group_edge_attrs = list(edge_attrs)\n",
    "    if group_edge_attrs is not None:\n",
    "        xs = []\n",
    "        for key in group_edge_attrs:\n",
    "            key = f'edge_{key}' if key in node_attrs else key\n",
    "            x = data[key]\n",
    "            x = x.view(-1, 1) if x.dim() <= 1 else x\n",
    "            xs.append(x)\n",
    "            del data[key]\n",
    "        data.edge_attr = torch.cat(xs, dim=-1)\n",
    "\n",
    "    if data.x is None and data.pos is None:\n",
    "        data.num_nodes = G.number_of_nodes()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f8d29-26ab-4740-9fa2-915b7ebf3d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adding this function that was missing in our version \n",
    "from torch_geometric.typing import SparseTensor\n",
    "\n",
    "def to_edge_index(adj: Union[Tensor, SparseTensor]) -> Tuple[Tensor, Tensor]:\n",
    "\n",
    "    if isinstance(adj, SparseTensor):\n",
    "        row, col, value = adj.coo()\n",
    "        if value is None:\n",
    "            value = torch.ones(row.size(0), device=row.device)\n",
    "        return torch.stack([row, col], dim=0), value\n",
    "\n",
    "    if adj.requires_grad:\n",
    "        # Calling adj._values() will return a detached tensor.\n",
    "        # Use `adj.coalesce().values()` instead to track gradients.\n",
    "        adj = adj.coalesce()\n",
    "        return adj.indices(), adj.values()\n",
    "\n",
    "    return adj._indices(), adj._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f742797-8af0-46c0-b3a1-dd9d8ce7f0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# label indices for node and edge classes\n",
    "label_dict = {\n",
    "        \"Point\": 0,\n",
    "        \"Line\": 1,\n",
    "        \"Circle\": 2,\n",
    "        \"Ellipse\": 3,\n",
    "        \"Spline\": 4,\n",
    "        \"Conic\": 5,\n",
    "        \"Arc\": 6,\n",
    "        \"External\": 7,\n",
    "        \"Stop\": 8,\n",
    "        \"Unknown\": 9,\n",
    "        \"SN_Start\": 10,\n",
    "        \"SN_End\": 11,\n",
    "        \"SN_Center\": 12\n",
    "    }\n",
    "\n",
    "useful_nodes_dict = {\n",
    "        \"Point\": 0,\n",
    "        \"Line\": 1,\n",
    "        \"Circle\": 2,\n",
    "        \"Ellipse\": 3,\n",
    "        \"Spline\": 4,\n",
    "        \"Conic\": 5,\n",
    "        \"Arc\": 6,\n",
    "        \"External\": 7,\n",
    "        \"Stop\": 8,\n",
    "        \"Unknown\": 9\n",
    "    }\n",
    "\n",
    "edge_dict = {\n",
    "    \"Coincident\": 0,\n",
    "    \"Projected\": 1,\n",
    "    \"Mirror\": 2,\n",
    "    \"Distance\": 3,\n",
    "    \"Horizontal\": 4,\n",
    "    \"Parallel\": 5,\n",
    "    \"Vertical\": 6,\n",
    "    \"Tangent\": 7,\n",
    "    \"Length\": 8,\n",
    "    \"Perpendicular\": 9,\n",
    "    \"Midpoint\": 10,\n",
    "    \"Equal\": 11,\n",
    "    \"Diameter\": 12,\n",
    "    \"Offset\": 13,\n",
    "    \"Radius\": 14,\n",
    "    \"Concentric\": 15,\n",
    "    \"Fix\": 16,\n",
    "    \"Angle\": 17,\n",
    "    \"Circular_Pattern\": 18,\n",
    "    \"Pierce\": 19,\n",
    "    \"Linear_Pattern\": 20,\n",
    "    \"Centerline_Dimension\": 21,\n",
    "    \"Intersected\": 22,\n",
    "    \"Silhoutted\": 23,\n",
    "    \"Quadrant\": 24,\n",
    "    \"Normal\": 25,\n",
    "    \"Minor_Diameter\": 26,\n",
    "    \"Major_Diameter\": 27,\n",
    "    \"Rho\": 28,\n",
    "    \"Unknown\": 29,\n",
    "    \"Subnode\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d044628-b8a6-455f-bcc1-03e61a15e72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracts features from nodes (positions, labels, etc.) \n",
    "from torch_geometric.utils import degree\n",
    "def get_sketch_features(graph, feature_dim):\n",
    "    x = torch.zeros([graph.num_nodes, feature_dim])\n",
    "\n",
    "    for idx, p in enumerate(graph.parameters):\n",
    "        \n",
    "        # add one hot encoding to feature vector for node label\n",
    "        #onePos = label_dict[graph.label[idx]]/7\n",
    "        #for i in range(0, 14):\n",
    "        #    x[idx, i] = 1 if onePos==i else 0\n",
    "        x[idx, label_dict[graph.label[idx]]] = 1\n",
    "        # convert label text into a feature value\n",
    "        #x[idx, 14] = label_dict[graph.label[idx]]/7\n",
    "        \n",
    "        param_dict = json.loads(p)\n",
    "        for i, k in enumerate(param_dict.keys()):\n",
    "            \n",
    "            if i+2 == feature_dim:\n",
    "                break\n",
    "            \n",
    "            # convert each parameter value into a feature value\n",
    "            x[idx, i+15] = float(param_dict[k])\n",
    "        \n",
    "        x[idx, -1] = degree(graph.edge_index[0], graph.num_nodes)[idx]\n",
    "        #print(idx, p)\n",
    "        #print(x[idx])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2922796-03d3-4c5e-8e59-ff0cd4f6cdaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (UNUSED) Prepares ground truth for node label prediction\n",
    "def get_sketch_attr_y(graph):\n",
    "    y = torch.zeros([graph.num_nodes, 1], dtype=torch.int64)\n",
    "\n",
    "    for i, l in enumerate(graph.label):\n",
    "        y[i, 0] = label_dict[l]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c801bc2-3d6a-410b-8720-aa520b38893d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generates adjacency matrix\n",
    "def get_sketch_adj(graph):\n",
    "    tst = T.ToSparseTensor()\n",
    "    return tst(graph).adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5208fb68-5f60-43bb-a58f-948c29c5fb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracts edge labels as features vectors for edges\n",
    "def get_sketch_edge_attr(graph):\n",
    "    dim = 31\n",
    "    edge_attr = torch.zeros([len(graph.edge_label), dim])\n",
    "    for idx, l in enumerate(graph.edge_label):\n",
    "        edge_attr[idx, edge_dict[l]] = 1\n",
    "    return edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ac7c0-a324-460c-a50b-24c18d6815a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# converts node/edge sequences from sketchgraphs into a sequence of one hot encoded vectors, representing node/edge classes\n",
    "def get_sketchgraph_node_constraint_sequence(sg, graph):\n",
    "    y = torch.zeros((len(sg)-1), dtype=torch.long)\n",
    "    node_idx=0\n",
    "    edge_idx=0\n",
    "    for idx, elem in enumerate(sg):\n",
    "        if type(elem) == sketchgraphs.data.sequence.NodeOp and not elem.label == sketchgraphs.data._entity.EntityType.Stop:\n",
    "            y[idx] = label_dict[graph.label[node_idx]]  \n",
    "            node_idx+=1\n",
    "        elif type(elem) == sketchgraphs.data.sequence.EdgeOp:\n",
    "            y[idx] = 13+edge_dict[graph.edge_label[edge_idx]]\n",
    "            edge_idx+=1\n",
    "    return y\n",
    "\n",
    "\n",
    "# the name of the method\n",
    "def convert_sketchgraph_to_pytorch(sg):\n",
    "    # convert first to pyGraphViz graph using sketchgraph's function\n",
    "    pgv_graph = sketchgraphs.data.sequence.pgvgraph_from_sequence(sg)\n",
    "    # then to networkx graph\n",
    "    nx_graph = nx.Graph(pgv_graph)\n",
    "    # finally to pyTorch graph\n",
    "    graph = from_networkx(nx_graph)\n",
    "    return graph\n",
    "\n",
    "# prepare all data our graphs need for learning\n",
    "def assign_attributes_to_graph(graph):\n",
    "    graph.x = get_sketch_features(graph, 30)\n",
    "    graph.y = get_sketch_attr_y(graph)\n",
    "    graph.adj_t = get_sketch_adj(graph)\n",
    "    graph.edge_index = to_edge_index(graph.adj_t)[0]\n",
    "    graph.edge_attr = get_sketch_edge_attr(graph)\n",
    "    return graph\n",
    "\n",
    "# generates a sequence of graphs during construction, not the most efficient way, but it works\n",
    "def get_sketchgraph_graph_sequence(sg, include_sequences=False):\n",
    "    generated_graph = []\n",
    "    sg_sequences = []\n",
    "    sequence = []\n",
    "    for elem in sg:\n",
    "        generated_graph.append(elem)\n",
    "        sg_sequences.append(generated_graph.copy())\n",
    "        new_graph = convert_sketchgraph_to_pytorch(generated_graph)\n",
    "        if not hasattr(new_graph, 'edge_label'):\n",
    "            new_graph.edge_label = []\n",
    "        new_graph = assign_attributes_to_graph(new_graph)\n",
    "        sequence.append(new_graph)\n",
    "    return sequence, sg_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8009f-a65d-4f4c-8ac6-d0b6804f14fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom dataset class of custom attributes\n",
    "from torch_geometric.data import Dataset\n",
    "class SketchgraphDataset(Dataset):\n",
    "    def __init__(self, start_idx, end_idx, transform=None, pre_transform=None, pre_filter=None, include_sequences=False):\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.data = []\n",
    "        seq_data = flat_array.load_dictionary_flat('datasets/sg_t16_validation.npy')\n",
    "\n",
    "        sketchgraps_list = seq_data['sequences'][start_idx:end_idx]\n",
    "\n",
    "\n",
    "        \n",
    "        for sg in sketchgraps_list:\n",
    "\n",
    "            graph = convert_sketchgraph_to_pytorch(sg)\n",
    "            \n",
    "            if not hasattr(graph, 'edge_label'):\n",
    "                continue\n",
    "\n",
    "            # next we need to add required attributes: x, y, adj_t\n",
    "            graph.x = get_sketch_features(graph, 30)\n",
    "            #graph.y = get_sketch_attr_y(graph)\n",
    "            graph.adj_t = get_sketch_adj(graph)\n",
    "            graph.edge_index = to_edge_index(graph.adj_t)[0]\n",
    "            graph.edge_attr = get_sketch_edge_attr(graph)\n",
    "            graph.seq, sg_sequence = get_sketchgraph_graph_sequence(sg, include_sequences)\n",
    "            #print(graph.seq)\n",
    "            graph.seq_y = get_sketchgraph_node_constraint_sequence(sg, graph)\n",
    "            if include_sequences:\n",
    "                graph.sg_sequences = sg_sequence\n",
    "                #print(len(graph.sg_sequences[3]))\n",
    "            self.data.append(graph)\n",
    "            \n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05dfec-3d6e-43b6-869d-c29c31195180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sketchgraphs\n",
    "import networkx as nx\n",
    "from sketchgraphs.data import flat_array\n",
    "\n",
    "train_dataset = SketchgraphDataset(0, 300)\n",
    "#test_dataset = SketchgraphDataset(101, 111)\n",
    "    \n",
    "data_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "#next(iter(data_loader)).seq_y\n",
    "\n",
    "val_dataset = SketchgraphDataset(500, 700)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df443b8-1d99-438f-a22c-58d0597bd8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple MLP for NNConv layer for including edge features in predictions\n",
    "class nnconvnn(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(nnconvnn, self).__init__()\n",
    "        \n",
    "        self.simpleLin = torch.nn.Linear(31, input_dim*output_dim)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.simpleLin.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.simpleLin(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2c2e3-d660-4efe-8182-5021ac2cd2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class newrnnmodel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, output_dim_second, num_nnconv_layers):\n",
    "        super(newrnnmodel, self).__init__()\n",
    "        self.layer_count = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "        self.input_gcn = torch.nn.ModuleList()\n",
    "        self.input_gcn.append(NNConv(30, hidden_size, nnconvnn(30, hidden_size)))\n",
    "        #self.bns = torch.nn.ModuleList()\n",
    "        for i in range(num_nnconv_layers-1):\n",
    "            self.input_gcn.append(NNConv(hidden_size, hidden_size, nnconvnn(hidden_size, hidden_size)))\n",
    "            \n",
    "        #for i in range(num_nnconv_layers-1):\n",
    "        #    self.bns.append(torch.nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "        self.rnn_class = torch.nn.RNN(hidden_size, hidden_size, self.layer_count) # batch first = True means the first dimension is batch size\n",
    "\n",
    "        self.mlp_pre_rnn = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.mlp_class = torch.nn.Linear(hidden_size, output_dim_second)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "\n",
    "        self.rnn_class.reset_parameters()\n",
    "        self.mlp_class.reset_parameters()\n",
    "        for l in range(len(self.input_gcn)):\n",
    "            self.input_gcn[l].reset_parameters()\n",
    "            \n",
    "        #for l in range(len(self.input_gcn)):\n",
    "        #    torch.nn.init.xavier_uniform(self.input_gcn[l].weight.data)\n",
    "        for l in range(len(self.rnn_class.all_weights)):\n",
    "            torch.nn.init.xavier_uniform_(self.rnn_class.all_weights[l][0])\n",
    "            torch.nn.init.xavier_uniform_(self.rnn_class.all_weights[l][1])\n",
    "        torch.nn.init.xavier_uniform_(self.mlp_pre_rnn.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp_class.weight)\n",
    "        \n",
    "    def forward(self, graph_sequence):\n",
    "\n",
    "        hidden = torch.zeros((self.layer_count, self.hidden_size), dtype=torch.float).to(device)\n",
    "        F.dropout.training = self.training\n",
    "        output = torch.tensor([]).to(device)\n",
    "        for g in graph_sequence:\n",
    "            x = g.x\n",
    "            all_layers_embeddings = None\n",
    "            for l in range(len(self.input_gcn)):\n",
    "                x = self.input_gcn[l](x, g.edge_index, g.edge_attr)\n",
    "                x = F.relu(x)\n",
    "                if all_layers_embeddings == None:\n",
    "                    all_layers_embeddings = global_mean_pool(x, torch.zeros((g.x.size(0)), dtype=torch.long).to(device))\n",
    "                else:\n",
    "                    all_layers_embeddings += global_mean_pool(x, torch.zeros((g.x.size(0)), dtype=torch.long).to(device))\n",
    "            #print(all_layers_embeddings.shape)\n",
    "            #x = global_mean_pool(all_layers_embeddings, torch.zeros((g.x.size(0)), dtype=torch.long).to(device))\n",
    "            x = all_layers_embeddings\n",
    "            x = self.mlp_pre_rnn(x)\n",
    "            x, hidden = self.rnn_class(x, hidden)\n",
    "            x = self.mlp_class(x)\n",
    "            x = self.softmax(x)\n",
    "            output = torch.cat((output, x))\n",
    "        return output, hidden.detach()\n",
    "        \n",
    "    def predict_next(self, sequence):\n",
    "        pred, hidden = self.forward(sequence)\n",
    "        return torch.argmax(pred[-1], dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e18b3-993a-4af2-a193-72a8ccd90474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn = newrnnmodel(30, 16, 15+31, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258644a-7304-486c-8fce-f3eaa61f915a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "\n",
    "optimizer_class = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
    "loss_fn = F.nll_loss\n",
    "#loss_fn = F.mse_loss\n",
    "epochs = 30\n",
    "rnn.train()\n",
    "\n",
    "# (training loop)\n",
    "for e in range(epochs):\n",
    "    loss_avg = 0\n",
    "    count = 0\n",
    "    acc = 0\n",
    "    for batch in iter(data_loader):\n",
    "        count+=1\n",
    "        batch.to(device)\n",
    "\n",
    "        optimizer_class.zero_grad()\n",
    "        pred_class, _ = rnn.forward(batch.seq[0])\n",
    "        #print(pred_type)\n",
    "        #print(pred_class)\n",
    "        #print(batch.seq_y.size())\n",
    "        loss_class = loss_fn(pred_class[:-1], batch.seq_y)\n",
    "        pred_index = torch.argmax(pred_class[:-1], dim=1)\n",
    "        acc += torch.sum(pred_index==batch.seq_y).item() / len(batch.seq_y)\n",
    "        loss_class.backward()\n",
    "        \n",
    "        loss_avg += loss_class.item()\n",
    "        \n",
    "\n",
    "        optimizer_class.step()\n",
    "        \n",
    "        \n",
    "    print(loss_avg/count, \"Acc: \" + str(acc/count * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344755a9-cd8f-4742-b75c-89e4ec029632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing model performance on unseen graph sequences\n",
    "rnn.eval()\n",
    "acc = 0\n",
    "count = 0\n",
    "loss_avg = 0\n",
    "for batch in iter(val_loader):\n",
    "    count+=1\n",
    "    batch.to(device)\n",
    "    pred_class,_ = rnn.forward(batch.seq[0])\n",
    "    loss_class = loss_fn(pred_class[:-1], batch.seq_y)\n",
    "    pred_index = torch.argmax(pred_class[:-1], dim=1)\n",
    "    acc += torch.sum(pred_index==batch.seq_y).item() / len(batch.seq_y)\n",
    "    loss_avg += loss_class.item()\n",
    "print(loss_avg/count, \"Acc: \" + str(acc/count * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93737d2-6b87-4189-af63-1404b2a81c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing on 3 example graphs\n",
    "example_graphs = SketchgraphDataset(2130, 2160, include_sequences=True)\n",
    "\n",
    "for idx, g in enumerate(example_graphs):\n",
    "    g.to(device)\n",
    "    first_useful_predicted = False\n",
    "    second_useful_predicted = False\n",
    "    after_image_shown = False\n",
    "    end_index = 12\n",
    "    while not after_image_shown and end_index < len(g.seq):\n",
    "        pred = rnn.predict_next(g.seq[0:end_index])\n",
    "        index = pred.item()\n",
    "        if index <= 12:\n",
    "            is_useful_node = list(label_dict.keys())[index] in useful_nodes_dict\n",
    "            if is_useful_node:\n",
    "                print(\"Predicted item index: \" + str(index) + \" (\" + str(list(label_dict.keys())[index]) + \")\")\n",
    "                print(\"Correct item index: \" + str(g.seq_y[end_index-1].item()))\n",
    "                sketch_before = datalib.sketch_from_sequence(g.sg_sequences[end_index])\n",
    "                datalib.render_sketch(sketch_before)\n",
    "            \n",
    "                sketch_after = datalib.sketch_from_sequence(g.sg_sequences[-1 if end_index+5 >= len(g.sg_sequences) else end_index+5])\n",
    "                datalib.render_sketch(sketch_after)\n",
    "                after_image_shown=True\n",
    "                break\n",
    "                \n",
    "            end_index+=1\n",
    "        else:\n",
    "            #print(index)\n",
    "            #print(list(edge_dict.keys())[index-15])\n",
    "            end_index+=1\n",
    "    #print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a59e2f-3e12-4356-a338-c8c019130979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
