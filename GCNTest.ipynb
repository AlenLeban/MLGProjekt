{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "from collections import defaultdict\n",
    "from typing import Any, Iterable, List, Optional, Tuple, Union\n",
    "from torch import Tensor\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import NNConv\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here is the modified to_networkx function that doesn't throw exceptions\n",
    "\n",
    "def from_networkx(\n",
    "    G: Any,\n",
    "    group_node_attrs: Optional[Union[List[str], all]] = None,\n",
    "    group_edge_attrs: Optional[Union[List[str], all]] = None,\n",
    ") -> 'torch_geometric.data.Data':\n",
    "    r\"\"\"Converts a :obj:`networkx.Graph` or :obj:`networkx.DiGraph` to a\n",
    "    :class:`torch_geometric.data.Data` instance.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph or networkx.DiGraph): A networkx graph.\n",
    "        group_node_attrs (List[str] or all, optional): The node attributes to\n",
    "            be concatenated and added to :obj:`data.x`. (default: :obj:`None`)\n",
    "        group_edge_attrs (List[str] or all, optional): The edge attributes to\n",
    "            be concatenated and added to :obj:`data.edge_attr`.\n",
    "            (default: :obj:`None`)\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        All :attr:`group_node_attrs` and :attr:`group_edge_attrs` values must\n",
    "        be numeric.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> edge_index = torch.tensor([\n",
    "        ...     [0, 1, 1, 2, 2, 3],\n",
    "        ...     [1, 0, 2, 1, 3, 2],\n",
    "        ... ])\n",
    "        >>> data = Data(edge_index=edge_index, num_nodes=4)\n",
    "        >>> g = to_networkx(data)\n",
    "        >>> # A `Data` object is returned\n",
    "        >>> from_networkx(g)\n",
    "        Data(edge_index=[2, 6], num_nodes=4)\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "\n",
    "    from torch_geometric.data import Data\n",
    "\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "    G = G.to_directed() if not nx.is_directed(G) else G\n",
    "\n",
    "    if isinstance(G, (nx.MultiGraph, nx.MultiDiGraph)):\n",
    "        edges = list(G.edges(keys=False))\n",
    "    else:\n",
    "        edges = list(G.edges)\n",
    "\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    data = defaultdict(list)\n",
    "\n",
    "    if G.number_of_nodes() > 0:\n",
    "        node_attrs = list(next(iter(G.nodes(data=True)))[-1].keys())\n",
    "    else:\n",
    "        node_attrs = {}\n",
    "\n",
    "    if G.number_of_edges() > 0:\n",
    "        edge_attrs = list(next(iter(G.edges(data=True)))[-1].keys())\n",
    "    else:\n",
    "        edge_attrs = {}\n",
    "\n",
    "    for i, (_, feat_dict) in enumerate(G.nodes(data=True)):\n",
    "        if set(feat_dict.keys()) != set(node_attrs):\n",
    "            raise ValueError('Not all nodes contain the same attributes')\n",
    "        for key, value in feat_dict.items():\n",
    "            data[str(key)].append(value)\n",
    "\n",
    "    for i, (_, _, feat_dict) in enumerate(G.edges(data=True)):\n",
    "        if set(feat_dict.keys()) != set(edge_attrs):\n",
    "            raise ValueError('Not all edges contain the same attributes')\n",
    "        for key, value in feat_dict.items():\n",
    "            key = f'edge_{key}' if key in node_attrs else key\n",
    "            data[str(key)].append(value)\n",
    "\n",
    "    for key, value in G.graph.items():\n",
    "        key = f'graph_{key}' if key in node_attrs else key\n",
    "        data[str(key)] = value\n",
    "\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, (tuple, list)) and isinstance(value[0], Tensor):\n",
    "            data[key] = torch.stack(value, dim=0)\n",
    "        else:\n",
    "            try:\n",
    "                data[key] = torch.tensor(value)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    data['edge_index'] = edge_index.view(2, -1)\n",
    "    data = Data.from_dict(data)\n",
    "\n",
    "    if group_node_attrs is all:\n",
    "        group_node_attrs = list(node_attrs)\n",
    "    if group_node_attrs is not None:\n",
    "        xs = []\n",
    "        for key in group_node_attrs:\n",
    "            x = data[key]\n",
    "            x = x.view(-1, 1) if x.dim() <= 1 else x\n",
    "            xs.append(x)\n",
    "            del data[key]\n",
    "        data.x = torch.cat(xs, dim=-1)\n",
    "\n",
    "    if group_edge_attrs is all:\n",
    "        group_edge_attrs = list(edge_attrs)\n",
    "    if group_edge_attrs is not None:\n",
    "        xs = []\n",
    "        for key in group_edge_attrs:\n",
    "            key = f'edge_{key}' if key in node_attrs else key\n",
    "            x = data[key]\n",
    "            x = x.view(-1, 1) if x.dim() <= 1 else x\n",
    "            xs.append(x)\n",
    "            del data[key]\n",
    "        data.edge_attr = torch.cat(xs, dim=-1)\n",
    "\n",
    "    if data.x is None and data.pos is None:\n",
    "        data.num_nodes = G.number_of_nodes()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.typing import SparseTensor\n",
    "\n",
    "def to_edge_index(adj: Union[Tensor, SparseTensor]) -> Tuple[Tensor, Tensor]:\n",
    "    r\"\"\"Converts a :class:`torch.sparse.Tensor` or a\n",
    "    :class:`torch_sparse.SparseTensor` to edge indices and edge attributes.\n",
    "\n",
    "    Args:\n",
    "        adj (torch.sparse.Tensor or SparseTensor): The adjacency matrix.\n",
    "\n",
    "    :rtype: (:class:`LongTensor`, :class:`Tensor`)\n",
    "\n",
    "    Example:\n",
    "\n",
    "        >>> edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "        ...                            [1, 0, 2, 1, 3, 2]])\n",
    "        >>> adj = to_torch_coo_tensor(edge_index)\n",
    "        >>> to_edge_index(adj)\n",
    "        (tensor([[0, 1, 1, 2, 2, 3],\n",
    "                [1, 0, 2, 1, 3, 2]]),\n",
    "        tensor([1., 1., 1., 1., 1., 1.]))\n",
    "    \"\"\"\n",
    "    if isinstance(adj, SparseTensor):\n",
    "        row, col, value = adj.coo()\n",
    "        if value is None:\n",
    "            value = torch.ones(row.size(0), device=row.device)\n",
    "        return torch.stack([row, col], dim=0), value\n",
    "\n",
    "    if adj.requires_grad:\n",
    "        # Calling adj._values() will return a detached tensor.\n",
    "        # Use `adj.coalesce().values()` instead to track gradients.\n",
    "        adj = adj.coalesce()\n",
    "        return adj.indices(), adj.values()\n",
    "\n",
    "    return adj._indices(), adj._values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "        \"Point\": 0,\n",
    "        \"Line\": 1,\n",
    "        \"Circle\": 2,\n",
    "        \"Ellipse\": 3,\n",
    "        \"Spline\": 4,\n",
    "        \"Conic\": 5,\n",
    "        \"Arc\": 6,\n",
    "        \"External\": 7,\n",
    "        \"Stop\": 8,\n",
    "        \"Unknown\": 9,\n",
    "        \"SN_Start\": 11,\n",
    "        \"SN_End\": 12,\n",
    "        \"SN_Center\": 13\n",
    "    }\n",
    "\n",
    "edge_dict = {\n",
    "    \"Coincident\": 0,\n",
    "    \"Projected\": 1,\n",
    "    \"Mirror\": 2,\n",
    "    \"Distance\": 3,\n",
    "    \"Horizontal\": 4,\n",
    "    \"Parallel\": 5,\n",
    "    \"Vertical\": 6,\n",
    "    \"Tangent\": 7,\n",
    "    \"Length\": 8,\n",
    "    \"Perpendicular\": 9,\n",
    "    \"Midpoint\": 10,\n",
    "    \"Equal\": 11,\n",
    "    \"Diameter\": 12,\n",
    "    \"Offset\": 13,\n",
    "    \"Radius\": 14,\n",
    "    \"Concentric\": 15,\n",
    "    \"Fix\": 16,\n",
    "    \"Angle\": 17,\n",
    "    \"Circular_Pattern\": 18,\n",
    "    \"Pierce\": 19,\n",
    "    \"Linear_Pattern\": 20,\n",
    "    \"Centerline_Dimension\": 21,\n",
    "    \"Intersected\": 22,\n",
    "    \"Silhoutted\": 23,\n",
    "    \"Quadrant\": 24,\n",
    "    \"Normal\": 25,\n",
    "    \"Minor_Diameter\": 26,\n",
    "    \"Major_Diameter\": 27,\n",
    "    \"Rho\": 28,\n",
    "    \"Unknown\": 29,\n",
    "    \"Subnode\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "def get_sketch_features(graph, feature_dim):\n",
    "    x = torch.zeros([graph.num_nodes, feature_dim])\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx, p in enumerate(graph.parameters):\n",
    "        \n",
    "        # add one hot encoding to feature vector for node label\n",
    "        onePos = label_dict[graph.label[idx]]/7\n",
    "        for i in range(0, 14):\n",
    "            x[idx, i] = 1 if onePos==i else 0\n",
    "        \n",
    "        # convert label text into a feature value\n",
    "        x[idx, 14] = label_dict[graph.label[idx]]/7\n",
    "        \n",
    "        param_dict = json.loads(p)\n",
    "        for i, k in enumerate(param_dict.keys()):\n",
    "            \n",
    "            if i+2 == feature_dim:\n",
    "                break\n",
    "            \n",
    "            # convert each parameter value into a feature value\n",
    "            x[idx, i+15] = float(param_dict[k])\n",
    "        \n",
    "        x[idx, -1] = degree(graph.edge_index[0], graph.num_nodes)[idx]\n",
    "        #print(idx, p)\n",
    "        #print(x[idx])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sketch_attr_y(graph):\n",
    "    y = torch.zeros([graph.num_nodes, 1], dtype=torch.int64)\n",
    "    #rint(graph.label)\n",
    "    \n",
    "    \n",
    "    for i, l in enumerate(graph.label):\n",
    "        y[i, 0] = label_dict[l]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sketch_adj(graph):\n",
    "    tst = T.ToSparseTensor()\n",
    "    return tst(graph).adj_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_large_graph(graphs):\n",
    "    bestN = 0\n",
    "    bestI = 0\n",
    "    for i, g in enumerate(graphs):\n",
    "        if len(g) > bestN:\n",
    "            bestN = len(g)\n",
    "            bestI = i\n",
    "    #print(bestI)\n",
    "    return graphs[bestI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sketch_edge_attr(graph):\n",
    "    dim = 31\n",
    "    edge_attr = torch.zeros([len(graph.edge_label), dim])\n",
    "    for idx, l in enumerate(graph.edge_label):\n",
    "        edge_attr[idx, edge_dict[l]] = 1\n",
    "    return edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom dataset class of custom attributes\n",
    "from torch_geometric.data import Dataset\n",
    "class SketchgraphDataset(Dataset):\n",
    "    def __init__(self, start_idx, end_idx, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(transform, pre_transform, pre_filter)\n",
    "        \n",
    "        self.data = []\n",
    "        seq_data = flat_array.load_dictionary_flat('datasets/sg_t16_validation.npy')\n",
    "        print(len(seq_data['sequences']))\n",
    "\n",
    "        #test_graph_seq = find_large_graph(seq_data['sequences'])\n",
    "        test_graph_seq = seq_data['sequences'][206778]\n",
    "        test_graph_seq1 = seq_data['sequences'][10]\n",
    "\n",
    "        sketchgraps_list = seq_data['sequences'][start_idx:end_idx]\n",
    "\n",
    "        for sg in sketchgraps_list:\n",
    "            #print(test_graph_seq)\n",
    "\n",
    "            # convert first to pyGraphViz graph using sketchgraph's function\n",
    "            pgv_graph = sketchgraphs.data.sequence.pgvgraph_from_sequence(sg)\n",
    "            #print(pgv_graph)\n",
    "\n",
    "            # then to networkx graph\n",
    "            nx_graph = nx.Graph(pgv_graph)\n",
    "            #print(nx_graph)\n",
    "\n",
    "            # finally to pyTorch graph\n",
    "            graph = from_networkx(nx_graph)\n",
    "            \n",
    "            if not hasattr(graph, 'edge_label'):\n",
    "                continue\n",
    "\n",
    "            # next we need to add required attributes: x, y, adj_t\n",
    "            graph.x = get_sketch_features(graph, 30)\n",
    "            graph.y = get_sketch_attr_y(graph)\n",
    "            graph.adj_t = get_sketch_adj(graph)\n",
    "            #print(graph.x)\n",
    "            graph.edge_index = to_edge_index(graph.adj_t)[0]\n",
    "            graph.edge_attr = get_sketch_edge_attr(graph)\n",
    "            #print(len(graph.edge_label))\n",
    "            self.data.append(graph)\n",
    "            \n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "\"\"\"def custom_collate(batch, b):\n",
    "    print(\"AAAAA\")\n",
    "    edge_label_batch = []\n",
    "    for b in batch:\n",
    "        #print(b.edge_label)\n",
    "        edge_label_batch.append(b.edge_label)\n",
    "    return edge_label_batch\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sketchgraphs\n",
    "import networkx as nx\n",
    "from sketchgraphs.data import flat_array\n",
    "\n",
    "train_dataset = SketchgraphDataset(0, 1023)\n",
    "test_dataset = SketchgraphDataset(1024, 2047)\n",
    "    \n",
    "data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "next(iter(data_loader)).x\n",
    "#for b in iter(data_loader):\n",
    "#    print(b)\n",
    "#print(graph)\n",
    "#print(graph.x)\n",
    "#print(graph.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dataset_name = 'ogbn-arxiv'\n",
    "    dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                  transform=T.ToSparseTensor())\n",
    "    data = dataset[0]\n",
    "    print(data)\n",
    "    #data = batch\n",
    "    \n",
    "\n",
    "\n",
    "    # Make the adjacency matrix to symmetric\n",
    "    data.adj_t = data.adj_t.to_symmetric()\n",
    "    #print(data.y)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # If you use GPU, the device should be cuda\n",
    "    print('Device: {}'.format(device))\n",
    "    data = data.to(device)\n",
    "    split_idx = dataset.get_idx_split()\n",
    "    print(split_idx['train'])\n",
    "    #train_idx = torch.LongTensor(range(0, data.num_nodes)).to(device)\n",
    "    #print(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class nnconvnn(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(nnconvnn, self).__init__()\n",
    "        \n",
    "        self.simpleLin = torch.nn.Linear(31, input_dim*output_dim)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.simpleLin.reset_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.simpleLin(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: Implement a function that initializes self.convs, \n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and \n",
    "        ## 'out_channels'. For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## For more information please refer to the documentation: \n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## (~10 lines of code)\n",
    "\n",
    "        #self.testnnconv = \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        for i in range(num_layers - 2):\n",
    "            self.convs.append(NNConv(input_dim, hidden_dim, nnconvnn(input_dim, hidden_dim)))\n",
    "        self.convs.append(NNConv(hidden_dim, hidden_dim, nnconvnn(hidden_dim, hidden_dim)))\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        for i in range(num_layers - 1):\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "        \n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # TODO: Implement a function that takes the feature tensor x and\n",
    "        # edge_index tensor adj_t and returns the output tensor as\n",
    "        # shown in the figure.\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as shown in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "        ## (~7 lines of code)\n",
    "        F.dropout.training = self.training\n",
    "        #x = self.testnnconv(x, edge_index, edge_attr)\n",
    "        for i in range(len(self.convs) - 1):\n",
    "            x = self.convs[i](x, edge_index, edge_attr)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x)\n",
    "        x = self.convs[-1](x, edge_index, edge_attr)\n",
    "        x = self.linear(x)\n",
    "        if self.return_embeds == False:\n",
    "            x = self.softmax(x)\n",
    "        out = x\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, loader, train_idx, optimizer, loss_fn):\n",
    "    # TODO: Implement a function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slice the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "    ## (~4 lines of code)\n",
    "    for batch in iter(loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        o = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        # o = o[train_idx] # we train on the whole graphs now\n",
    "        #print(o)\n",
    "        #print(batch.y.squeeze())\n",
    "        loss = loss_fn(o, batch.y.squeeze(1))\n",
    "        #########################################\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, loader, split_idx, evaluator, save_model_results=False):\n",
    "    # TODO: Implement a function that tests the model by \n",
    "    # using the given split_idx and evaluator.\n",
    "    model.eval()\n",
    "\n",
    "    # The output of model on all data\n",
    "    out = None\n",
    "    train_acc = 0\n",
    "    valid_acc = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        count+=1\n",
    "        batch = batch.to(device)\n",
    "        ############# Your code here ############\n",
    "        ## (~1 line of code)\n",
    "        ## Note:\n",
    "        ## 1. No index slicing here\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        #########################################\n",
    "\n",
    "        y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "        \n",
    "        #if count == 1:\n",
    "            #print(y_pred, batch.y)\n",
    "        \n",
    "        train_acc += evaluator.eval({\n",
    "            'y_true': batch.y,\n",
    "            'y_pred': y_pred,\n",
    "        })['acc']\n",
    "        valid_acc += evaluator.eval({\n",
    "            'y_true': batch.y,\n",
    "            'y_pred': y_pred,\n",
    "        })['acc']\n",
    "        test_acc += evaluator.eval({\n",
    "            'y_true': batch.y,\n",
    "            'y_pred': y_pred,\n",
    "        })['acc']\n",
    "\n",
    "    train_acc /= count\n",
    "    valid_acc /= count\n",
    "    test_acc /= count\n",
    "\n",
    "    if save_model_results:\n",
    "        print (\"Saving Model Predictions\")\n",
    "\n",
    "        data = {}\n",
    "        data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "        # Save locally as csv\n",
    "        df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please do not change the args\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    args = {\n",
    "      'device': device,\n",
    "      'num_layers': 3,\n",
    "      'hidden_dim': 256,\n",
    "      'dropout': 0.5,\n",
    "      'lr': 0.01,\n",
    "      'epochs': 100,\n",
    "    }\n",
    "    args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    model = GCN(30, args['hidden_dim'],\n",
    "              14, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "    evaluator = Evaluator(name='ogbn-arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please do not change these args\n",
    "# Training should take <10min using GPU runtime\n",
    "import copy\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # reset the parameters to initial random value\n",
    "    model.reset_parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    loss_fn = F.nll_loss\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_acc = 0\n",
    "\n",
    "    for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "        loss = train(model, data_loader, [], optimizer, loss_fn)\n",
    "        result = test(model, test_loader, [], evaluator)\n",
    "        train_acc, valid_acc, test_acc = result\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_acc:.2f}%, '\n",
    "              f'Valid: {100 * valid_acc:.2f}% '\n",
    "              f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test(model, data_loader, [], evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
